{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuyan2000/DATAAI961-YuyanZhao/blob/main/Coding_and_Testing_with_the_fmatrix_Data_Structure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnmxx8KrObaX"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The reference for matrix computations in CUDA is the cuBLAS library. \n",
        "Similar to other basic linear algebra (BLAS) libraries, cuBLAS does not\n",
        "have a particular data structure for representing matrics. Instead, the data\n",
        "in the matrix is stored in a 1D array, and it is up to the user to keep track\n",
        "of matrix dimensions, memory allocation, etc.\n",
        "In our experience, this is very error prone and coders end up spending hours \n",
        "hunting for bugs that are often just typos. This is one of the reasons that frameworks like PyTorch and Tensorflow provide their own tensor data structures.\n",
        "We do the same, but keep the data structure as simple as possible so that you can understand easily what's under the hood.\n",
        "\n",
        "We propose a __simple cuBLAS-compatible data structure__, called `fmatrix`, for representing matrices\n",
        "with single precision, and provide a collection of __functions for routine tasks__ such as \n",
        "- easy access to matrix elements (no need to compute element addresses),\n",
        "- creating matrices (allocating memory) on the host and the device, including matrices with random values,\n",
        "- copying matrices between host and device,\n",
        "- printing matrices and reading/writing with CSV files.\n",
        "\n",
        "We highly encourage you to look at how these functions are coded, and then use them in their own code rather than directly working with the 1D array data. This will make their code faster to develop, more readable and help avoid bugs. This is not just about understanding how the `fmatrix` code works -- the same principles are at work in __all__ the deep learning frameworks.\n",
        "\n",
        "In this notebook, we first show the `fmatrix` structure and accompanying functions, then give examples of matrix functions implemented with `fmatrix`, and finally show different ways to test that these functions work as intended.\n",
        "For exhaustive, automated testing, we generate and check test cases with Numpy. Comparing the output of the GPU code with established software should greatly increase the confidence. The same principle could be applied to compare with the output of high-level frameworks like PyTorch or Tensorflow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwd38XvZK2sy"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm8KscV-wx3m"
      },
      "source": [
        "Check that the NVIDIA compiler is present."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6ewR7_sHJ00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d224186b-3e47-4687-f90d-7ba3d315fb73"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po-TEvrWMJ_a"
      },
      "source": [
        "## CUDA Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-lgwhE1N5_7",
        "outputId": "450c0ecf-022d-41be-e186-02d4b5f2a3c2"
      },
      "source": [
        "%%writefile cuda_stuff.cuh\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "#ifndef cuda_stuff_H\n",
        "#define cuda_stuff_H\n",
        "\n",
        "/* transform matrix index to vector offset\n",
        "   Since CUDA uses column major, \n",
        "   nb_rows = number of rows */\n",
        "#define IDX2C(i,j,nb_rows) (((j)*(nb_rows))+(i))\n",
        " \n",
        "//MACRO TO DEBUGG CUDA FUNCTIONS\n",
        "/** Error checking,\n",
        " *  taken from https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api\n",
        " */\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess) \n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "/** Error checking for use with CUDA Dynamic Parallelism */\n",
        "/*\n",
        "#define cdpErrchk(ans) { cdpAssert((ans), __FILE__, __LINE__); }\n",
        "__device__ void cdpAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      printf(\"GPU kernel assert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) assert(0);\n",
        "   }\n",
        "}\n",
        "*/\n",
        "void device_synchronize();\n",
        "\n",
        "#endif\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_stuff.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iivrxLaYOYPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f3fe19-8f63-4675-cd28-b01d45a9cba7"
      },
      "source": [
        "%%writefile cuda_stuff.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include \"cuda_stuff.cuh\"\n",
        "\n",
        "void device_synchronize(){\n",
        "    gpuErrchk(cudaDeviceSynchronize());\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_stuff.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fsEMpauK8lW"
      },
      "source": [
        "# The fmatrix Data Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD7TXq-1L8tL"
      },
      "source": [
        "Similar to cuBLAS, a 2D matrix is represented by a 1D array that stores one column of the matrix after another (this is called _linearization_).\n",
        "The `fmatrix` structure contains a `data` pointer to such an array, which is 100% compatible with cuBLAS. In addition, it stores the number of columns and rows in the matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A97U902HMog4",
        "outputId": "60a3effd-82aa-4697-f215-1b95deee46c5"
      },
      "source": [
        "%%writefile fmatrix.cuh\n",
        "#ifndef fmatrices_H\n",
        "#define fmatrices_H\n",
        "#include \"cuda_stuff.cuh\" // for IDX2C\n",
        "\n",
        "////////////////////////////////////////\n",
        "// basic data structure and access macro\n",
        "////////////////////////////////////////\n",
        "typedef struct {\n",
        "    float* data;\n",
        "    int cols;\n",
        "    int rows;\n",
        "} fmatrix;\n",
        "\n",
        "/** Access element (i,j) of matrix M \n",
        " *\n",
        " *  Usage example:\n",
        " *  For computing A = B^T + C), loop over i and j with:\n",
        " *    getfm(A,i,j) = getfm(B,j,i) + getfm(C,i,j);\n",
        " **/\n",
        "#define getfm(M,i,j) (M.data[IDX2C(i,j,M.rows)])\n",
        "\n",
        "////////////////////////////////////////\n",
        "// utility functions\n",
        "////////////////////////////////////////\n",
        "/** Returns the number of elements in the matrix.\n",
        " *\n",
        " *  Useful for computing, e.g., the size\n",
        " *  of a 1D-vector that contains the same numbers.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "int fmatrix_elements(fmatrix mat);\n",
        "\n",
        "/** Returns the memory occupied by the matrix elements in bytes\n",
        " *  (not including the variables in the struct mat).\n",
        " *\n",
        " *  Useful for allocating memory for the data.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "int fmatrix_size(fmatrix mat);\n",
        "\n",
        "/** Assert that the matrix is coherent: all fields nonzero. */\n",
        " __host__\n",
        " __device__\n",
        "void fmatrix_assert(fmatrix mat);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Create, copy, destroy\n",
        "////////////////////////////////////////\n",
        "/** Allocate memory on host */\n",
        "fmatrix fmatrix_create_on_host(int rows, int cols);\n",
        "\n",
        "/** Allocate memory on device */\n",
        "fmatrix fmatrix_create_on_device(int rows, int cols);\n",
        "\n",
        "/** Create a matrix representing columns [a,b) of M. \n",
        " *  Note that the new matrix uses a pointer to the\n",
        " *  data of M. The data is not copied to a new location.\n",
        " *  If M is destroyed, this matrix is useless.\n",
        " */\n",
        "fmatrix fmatrix_subcolumns(fmatrix M, int a, int b);\n",
        "\n",
        "/** Copy data from matrix on device to host \n",
        " *  (no memory allocation). */\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device);\n",
        "\n",
        "/** Copy data from matrix on host to device\n",
        " *  (no memory allocation). */\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device);\n",
        "\n",
        "/** Copy matrix from device to host, allocating new memory. */\n",
        "fmatrix fmatrix_copy_to_host(fmatrix mat_device);\n",
        "\n",
        "/** Copy matrix from host to device, allocating new memory. */\n",
        "fmatrix fmatrix_copy_to_device(fmatrix mat_host);\n",
        "\n",
        "/** Free data memory on host. \n",
        " *  This zeros out the data pointer of the fmatrix struct,\n",
        " *  so a pointer is required. */\n",
        "void fmatrix_free_on_host(fmatrix* mat);\n",
        "\n",
        "/** Free data memory on device. \n",
        " *  This zeros out the data pointer of the fmatrix struct,\n",
        " *  so a pointer is required. */\n",
        "void fmatrix_free_on_device(fmatrix* mat);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Input and Output\n",
        "////////////////////////////////////////\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the host. \n",
        " *  If nb<0, print all rows. \n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "void fmatrix_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the device. \n",
        " *  If nb<0, print all rows. \n",
        " *\n",
        " *  This version copies the matrix to host first.\n",
        " */\n",
        "void fmatrix_device_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "/** Print a matrix to a csv file. \n",
        " *\n",
        " *  This version copies the matrix to host first.\n",
        " */\n",
        "void fmatrix_device_to_csv(const char* filename, fmatrix mat);\n",
        "\n",
        "/** Read a matrix from a csv file. \n",
        " *\n",
        " *  This version creates the matrix on the host first.\n",
        " */\n",
        "fmatrix fmatrix_device_from_csv(const char* filename);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Useful\n",
        "////////////////////////////////////////\n",
        "\n",
        "/** Create a matrix with random values between -1 and 1\n",
        " *  on the device */\n",
        "fmatrix fmatrix_create_random_on_device(int rows, int cols);\n",
        "\n",
        "#endif\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fmatrix.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGwZ36ifWQ-d",
        "outputId": "63676420-8a04-4817-a103-bb5556a24b5c"
      },
      "source": [
        "%%writefile fmatrix.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <curand.h>\n",
        "#include <curand_kernel.h>\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "// for reading CSV files, we use some C++\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <fstream>\n",
        "#include <string>\n",
        "\n",
        "int fmatrix_elements(fmatrix mat) {\n",
        "     return mat.cols*mat.rows;\n",
        "}\n",
        "\n",
        "int fmatrix_size(fmatrix mat) {\n",
        "    fmatrix_assert(mat);\n",
        "     return fmatrix_elements(mat) * sizeof(float);\n",
        "}\n",
        "\n",
        "void fmatrix_assert(fmatrix mat) {\n",
        "    assert(mat.data);\n",
        "    assert(mat.cols);\n",
        "    assert(mat.rows);\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_host(int rows, int cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    mat.data = (float*)malloc(fmatrix_size(mat)); \n",
        "    assert(mat.data);\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_device(int rows, int cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    gpuErrchk( \n",
        "        cudaMalloc((void **)&(mat.data), fmatrix_size(mat)) \n",
        "    );\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk( \n",
        "        cudaMemcpy( mat_device.data, mat_host.data, \n",
        "                   fmatrix_size(mat_host), \n",
        "                   cudaMemcpyHostToDevice \n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk(\n",
        "        cudaMemcpy( mat_host.data, mat_device.data,  \n",
        "                   fmatrix_size(mat_device), \n",
        "                   cudaMemcpyDeviceToHost \n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_copy_to_host(fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_device);\n",
        "    fmatrix mat_host = fmatrix_create_on_host(mat_device.rows, mat_device.cols);\n",
        "    fmatrix_data_to_host(mat_host,mat_device);\n",
        "    return mat_host;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_copy_to_device(fmatrix mat_host) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix mat_device = fmatrix_create_on_device(mat_host.rows, mat_host.cols);\n",
        "    fmatrix_data_to_device(mat_host,mat_device);\n",
        "    return mat_device;\n",
        "}\n",
        "\n",
        "/** We could do it like this, but it would not set our pointer M.data to 0. \n",
        "... fmatrix_free_on_host(M)\n",
        "void fmatrix_free_on_host(fmatrix mat) {\n",
        "    fmatrix_assert(mat);  \n",
        "  free(mat.data);\n",
        "  mat.data = 0;\n",
        "  mat.cols = 0;\n",
        "  mat.rows = 0;\n",
        "}\n",
        "*/\n",
        "\n",
        "void fmatrix_free_on_host(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);  \n",
        "  free(mat->data);\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "void fmatrix_free_on_device(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);  \n",
        "  gpuErrchk(cudaFree(mat->data));\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_subcolumns(fmatrix M, int a, int b) {\n",
        "    fmatrix_assert(M);  \n",
        "    fmatrix A = { \n",
        "        .data = &getfm(M,0,a),  \n",
        "        .cols = b-a,\n",
        "        .rows = M.rows \n",
        "    };\n",
        "    fmatrix_assert(A);  \n",
        "    return A;\n",
        "}\n",
        "\n",
        "\n",
        "__host__\n",
        "__device__\n",
        "void fmatrix_print(fmatrix mat, int nb){\n",
        "    if (nb<0 || nb > mat.rows) {\n",
        "        nb = mat.rows;\n",
        "    }\n",
        "    printf(\"[\\n\");\n",
        "    for (int i = 0 ; i < nb; i++){\n",
        "      for (int j = 0 ; j<mat.cols; j++){\n",
        "        printf(\"%f\", getfm(mat,i,j));\n",
        "        if (j+1<mat.cols) {\n",
        "          printf(\",\\t\");\n",
        "        }\n",
        "      }\n",
        "      if (i+1<nb) {\n",
        "        printf(\";\\n\");\n",
        "      }\n",
        "    }\n",
        "    if (nb < mat.rows) {\n",
        "      printf(\"\\n...\\n\");\n",
        "    }\n",
        "  printf(\"\\n]\\n\");\n",
        "}\n",
        "\n",
        "void fmatrix_device_print(fmatrix mat, int nb){\n",
        "   // allocate copy\n",
        "   fmatrix tmp = fmatrix_copy_to_host(mat);\n",
        "   fmatrix_print(tmp,nb);\n",
        "   fmatrix_free_on_host(&tmp);\n",
        "}\n",
        "\n",
        "void fmatrix_device_to_csv(const char* filename, fmatrix mat) {\n",
        "  // Open file\n",
        "  FILE* fp = fopen(filename, \"w\");\n",
        "  // allocate copy\n",
        "  fmatrix tmp = fmatrix_copy_to_host(mat);\n",
        "  for (int i = 0 ; i < tmp.rows; i++){\n",
        "    for (int j = 0 ; j<tmp.cols; j++){\n",
        "      // Note: %.15g gives 15 significant digits (full double precision)\n",
        "      fprintf(fp,\"%.15g\", getfm(tmp,i,j));\n",
        "      if (j+1<tmp.cols) {\n",
        "        fprintf(fp,\",\");\n",
        "      }\n",
        "    }\n",
        "    fprintf(fp,\"\\n\");\n",
        "  }\n",
        "  fmatrix_free_on_host(&tmp);\n",
        "  // Close file\n",
        "  fclose(fp);\n",
        "}\n",
        "\n",
        "__global__\n",
        "void fmatrix_create_random_on_device_kernel(fmatrix M) {\n",
        "    // choose a seed (here: the same each launch)\n",
        "    unsigned long seed = 0;\n",
        "    int sequence = 0;\n",
        "    // first, initialize the random numbers\n",
        "    curandState state;\n",
        "    curand_init(seed, sequence, 0, &state);\n",
        "    for (int i = 0; i < fmatrix_elements(M); ++i) {\n",
        "        // curand_uniform creates numbers between 0 and 1\n",
        "        M.data[i] = (curand_uniform(&state)-0.5)*2.0;\n",
        "    }\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_random_on_device(int rows, int cols) {\n",
        "    // Create an uninitialized matrix on the device\n",
        "    fmatrix M = fmatrix_create_on_device(rows,cols);\n",
        "    // Call a kernel with a single thread to fill the values\n",
        "    fmatrix_create_random_on_device_kernel<<<1,1>>>(M);\n",
        "\n",
        "    return M;\n",
        "}\n",
        "\n",
        "/* Count the number of rows and columns in a csv files (without headers) */\n",
        "void count_elements_in_csv(const char* filename, int* rows, int* cols) {\n",
        "  // Note: for the sake of convenience, we use some C++ functions here\n",
        "  using namespace std;\n",
        "\n",
        "  *rows = 0;\n",
        "  *cols = 0;\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "    while (getline(infile, row_as_string, '\\n')) {\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "        int tempcols = 0;\n",
        "        while (getline(line_stream, value, ',')) {\n",
        "          ++tempcols;\n",
        "        }\n",
        "        if (tempcols > *cols) {\n",
        "           *cols = tempcols;\n",
        "        }\n",
        "        ++(*rows);\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n",
        "/** Read the data from a csv file into an fmatrix on the host.\n",
        " *  Careful: We assume that the matrix has the right dimensions!\n",
        " *  Use count_elements_in_csv(...) to get the dimensions if\n",
        " *  unknown.\n",
        " */\n",
        "void fmatrix_fill_from_csv(fmatrix h_M,const char* filename) {\n",
        "  // Note: for the sake of convenience, we use some C++ functions here\n",
        "  using namespace std;\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "  int row = 0;\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "    while (getline(infile, row_as_string, '\\n')) {\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "        int col = 0;\n",
        "        while (getline(line_stream, value, ',')) {\n",
        "\t\t\t\t\tgetfm(h_M,row,col) = strtod(value.c_str(), NULL); \n",
        "          ++col;\n",
        "\t\t\t\t}\n",
        "        ++row;\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_device_from_csv(const char* filename) {\n",
        "  // first read the file to count the number of elements\n",
        "  int rows = 0;\n",
        "  int cols = 0;\n",
        "  count_elements_in_csv(filename,&rows,&cols);\n",
        "\n",
        "  // allocate the matrix on the host\n",
        "  fmatrix h_M = fmatrix_create_on_host(rows,cols);\n",
        "\n",
        "  // read the data into the host matrix\n",
        "  fmatrix_fill_from_csv(h_M,filename);\n",
        "\n",
        "  // copy the matrix to the device\n",
        "  fmatrix M = fmatrix_copy_to_device(h_M);\n",
        "  \n",
        "  // destroy the host matrix\n",
        "  fmatrix_free_on_host(&h_M);\n",
        "\n",
        "  return M;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fmatrix.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN57hYCW_Qug"
      },
      "source": [
        "# Writing Matrix Functions with fmatrix\n",
        "We will look at two examples that illustrate how to create, manipulate and compute using the fmatrix structure.\n",
        "The first example is the matrix transpose, which generates a new matrix.\n",
        "The second example is the matrix multiplication. It overwrites the data of an existing matrix with the result of the multiplication.\n",
        "\n",
        "We start by looking at the code. Testing the code will be discussed in the section that comes afterwards."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N45Tn8noN12W"
      },
      "source": [
        "## Matrix Addition\n",
        "Our first example is to add one matrix to another, multiplied by a scalar. \n",
        "We need to functions: One is a normal C function that is called on the host, the other is the kernel, whose code will be executed on the GPU. In this example, the host function doesn't do much more than launch the kernel.\n",
        "Have a look at the error checks, which ensure that both matrices are compatible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFrZCF7jOse1",
        "outputId": "492deacb-7a66-4aa4-f953-6da553122ee3"
      },
      "source": [
        "%%writefile fmatrix_add.cu\n",
        "#include \"fmatrix.cuh\"\n",
        "#include <assert.h>\n",
        "\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "__global__ \n",
        "void fmatrix_add_kernel(fmatrix P,float a,fmatrix Y) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / P.rows;\n",
        "    int i = idx % P.rows;\n",
        "    if (i < P.rows && j < P.cols ){\n",
        "        getfm(P,i,j) += a*getfm(Y,i,j);\n",
        "    }\n",
        "}\n",
        "\n",
        "/** Compute P = P + a*Y */\n",
        "void fmatrix_add(fmatrix P,float a,fmatrix Y) {\n",
        "    fmatrix_assert(P);\n",
        "    fmatrix_assert(Y);\n",
        "    assert(P.rows == Y.rows);\n",
        "    assert(P.cols == Y.cols);\n",
        "    int threadsPerBlock = fmatrix_elements(P);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_add_kernel<<< blocksPerGrid, threadsPerBlock >>>(P,a,Y);\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fmatrix_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the implementation for add doesn't include any synchronization. This is so that you can launch adds in parallel, which is perfectly fine if the date for both tasks is independent. Here's a small example:\n",
        "```\n",
        "// Without waiting:\n",
        "fmatrix_add(P1,a,Y1);\n",
        "fmatrix_add(P2,a,Y2);\n",
        "deviceSynchronize();\n",
        "\n",
        "// Waiting between each\n",
        "fmatrix_add(P1,a,Y1);\n",
        "deviceSynchronize();\n",
        "fmatrix_add(P2,a,Y2);\n",
        "deviceSynchronize();\n",
        "```"
      ],
      "metadata": {
        "id": "X0SLSDrV3CLJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnGphOO21Sc7"
      },
      "source": [
        "## Matrix Multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNY5FKdl19Bc"
      },
      "source": [
        "Here, we will create a new matrix A that contains the product of two matrices B and C.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g1XwwS419Bn",
        "outputId": "5b7bc6f0-d4c1-4e95-e5ee-6be5ca20e438"
      },
      "source": [
        "%%writefile fmatrix_mult.cu\n",
        "#include \"fmatrix.cuh\"\n",
        "#include <assert.h>\n",
        "\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "__global__\n",
        "void fmatrix_multiplication_kernel(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // Each thread multiplies one row of B with one column of C\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / A.rows;\n",
        "    int i = idx % A.rows;\n",
        "    if (i < A.rows && j < A.cols ){\n",
        "        getfm(A,i,j) = 0.0;\n",
        "        for (int k = 0; k < B.cols; ++k) {\n",
        "          getfm(A,i,j) += f*getfm(B,i,k)*getfm(C,k,j);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Compute A = f*B*C */\n",
        "void fmatrix_mult(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // First let's check for errors in the argument M.\n",
        "    // This can help a LOT when debugging.\n",
        "    // A,B,C need to have nonzero pointers etc.\n",
        "    // fmatrix_assert(A);\n",
        "    // fmatrix_assert(B);\n",
        "    // fmatrix_assert(C);\n",
        "    assert(A.rows == B.rows);\n",
        "    assert(A.cols == C.cols);\n",
        "    assert(B.cols == C.rows);\n",
        "    \n",
        "    // take one thread per element, and distribute\n",
        "    // over as many blocks as necessary given\n",
        "    // the hardware limit on the number of threads per block\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_multiplication_kernel<<< blocksPerGrid, threadsPerBlock >>>(A,f,B,C);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fmatrix_mult.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_16DcZBAebJ"
      },
      "source": [
        "# Testing the Matrix Functions\n",
        "\n",
        "According to the literature, 50% to 75% percent of development time is dedicated to testing, verifying and validating code. This percentage refers to professional software developers, who know how to set up tests. If you don't test your functions individually before using them in larger pieces of code, you can easily end up spending 95% to 99% of your time debugging.\n",
        "\n",
        "In the next sections, we will look at a few techniques to quickly set up tests, first for manual, visual inspection, and then for automatic testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkNoBBB1plBI"
      },
      "source": [
        "## Visual Inspection\n",
        "\n",
        "The following test code calls the add function on a random matrix and prints the result. Since the resulting values are easy to check manually, we can confirm that our function works simply by looking at the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1Z-dg_xv3A1",
        "outputId": "03e526fe-df6d-4525-8bb9-584aa784cfbb"
      },
      "source": [
        "%%writefile test.cu\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"fmatrix_add.cu\"\n",
        "\n",
        "int main() {\n",
        "    // create a random matrix\n",
        "    fmatrix M = fmatrix_create_random_on_device(3,5);\n",
        "    printf(\"original matrix:\\n\");\n",
        "    fmatrix_device_print(M);\n",
        "    // add the matrix to itself\n",
        "    fmatrix_add(M,1.0,M);\n",
        "    // print\n",
        "    printf(\"matrix added to itself:\\n\");\n",
        "    fmatrix_device_print(M);\n",
        "    // free the memory\n",
        "    fmatrix_free_on_device(&M);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYs_qHoSwgq4"
      },
      "source": [
        "!nvcc -arch=sm_35 -Wno-deprecated-gpu-targets -g -G -I /usr/local/cuda/samples/common/inc/ -L/usr/local/cuda/include test.cu fmatrix.cu cuda_stuff.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kfx5HK6wnrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f42f52a-294b-4800-c6f3-88a33892d964"
      },
      "source": [
        "!./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original matrix:\n",
            "[\n",
            "0.480439,\t-0.686023,\t-0.544713,\t-0.624402,\t0.949322;\n",
            "-0.123098,\t-0.857265,\t-0.341283,\t0.830767,\t0.094939;\n",
            "0.034025,\t-0.074983,\t-0.711869,\t0.080250,\t0.306321\n",
            "]\n",
            "matrix added to itself:\n",
            "[\n",
            "0.960877,\t-1.372046,\t-1.089427,\t-1.248804,\t1.898643;\n",
            "-0.246195,\t-1.714530,\t-0.682566,\t1.661534,\t0.189877;\n",
            "0.068051,\t-0.149966,\t-1.423739,\t0.160499,\t0.612641\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IThxMp1XgAsv"
      },
      "source": [
        "## Manual Comparison with Known Solution\n",
        "\n",
        "To test the matrix multiplication, we manually define input matrices.\n",
        "We also define the expected output, assuming we know the solution. Maybe we computed it by hand or with Matlab.\n",
        "Again, we visually compare the expected output with the known solution simply by printing both."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2kFIpPO1s8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96da7a69-4474-4b1e-f46e-7198d9c00103"
      },
      "source": [
        "%%writefile test.cu\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"fmatrix_mult.cu\"\n",
        "\n",
        "int main() {\n",
        "    // create two matrices on the host with given values\n",
        "    fmatrix h_B = fmatrix_create_on_host(2,3);\n",
        "    fmatrix h_C = fmatrix_create_on_host(3,2);\n",
        "    // B = [ 2, 3, 4; 5, 6, 7 ]\n",
        "    getfm(h_B,0,0) = 2;\n",
        "    getfm(h_B,0,1) = 3;\n",
        "    getfm(h_B,0,2) = 4;\n",
        "    getfm(h_B,1,0) = 5;\n",
        "    getfm(h_B,1,1) = 6;\n",
        "    getfm(h_B,1,2) = 7;\n",
        "    // C = [ -1, 2; -3, 4; -5, 6 ]\n",
        "    getfm(h_C,0,0) = -1;\n",
        "    getfm(h_C,0,1) = 2;\n",
        "    getfm(h_C,1,0) = -3;\n",
        "    getfm(h_C,1,1) = 4;\n",
        "    getfm(h_C,2,0) = -5;\n",
        "    getfm(h_C,2,1) = 6;\n",
        "    // copy the matrices to the device\n",
        "    fmatrix B = fmatrix_copy_to_device(h_B);\n",
        "    fmatrix C = fmatrix_copy_to_device(h_C);\n",
        "    printf(\"matrix B:\\n\");\n",
        "    fmatrix_device_print(B);\n",
        "    printf(\"matrix C:\\n\");\n",
        "    fmatrix_device_print(C);\n",
        "    // allocate matrix A\n",
        "    fmatrix A = fmatrix_create_on_device(2,2);\n",
        "    // compute A = 3.0*B*C\n",
        "    fmatrix_mult(A,3.0,B,C);\n",
        "    // print\n",
        "    printf(\"matrix A=3*B*C:\\n\");\n",
        "    fmatrix_device_print(A);\n",
        "    fmatrix h_A_expected = fmatrix_create_on_host(2,2);\n",
        "    // A_expected = [ -93, 120; -174, 228 ]\n",
        "    getfm(h_A_expected,0,0) = -93;\n",
        "    getfm(h_A_expected,0,1) = 120;\n",
        "    getfm(h_A_expected,1,0) = -174;\n",
        "    getfm(h_A_expected,1,1) = 228;\n",
        "    printf(\"expected A:\\n\");\n",
        "    fmatrix_print(h_A_expected);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIbBgkZH1s8Z"
      },
      "source": [
        "!nvcc -arch=sm_35 -Wno-deprecated-gpu-targets -g -G -I /usr/local/cuda/samples/common/inc/ -L/usr/local/cuda/include test.cu fmatrix.cu cuda_stuff.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4MDJHZ71s8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd7dd87-f1ad-42c8-fed2-2f413bc3d1aa"
      },
      "source": [
        "!./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matrix B:\n",
            "[\n",
            "2.000000,\t3.000000,\t4.000000;\n",
            "5.000000,\t6.000000,\t7.000000\n",
            "]\n",
            "matrix C:\n",
            "[\n",
            "-1.000000,\t2.000000;\n",
            "-3.000000,\t4.000000;\n",
            "-5.000000,\t6.000000\n",
            "]\n",
            "matrix A=3*B*C:\n",
            "[\n",
            "-93.000000,\t120.000000;\n",
            "-174.000000,\t228.000000\n",
            "]\n",
            "expected A:\n",
            "[\n",
            "-93.000000,\t120.000000;\n",
            "-174.000000,\t228.000000\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzlIT2mInHO9"
      },
      "source": [
        "## Comparison with Known Code (Numpy)\n",
        "For a test that is both easier to write and more reliable, let's use\n",
        "Python/Numpy to create the matrices, compute the correct result, and\n",
        "compare the result to the output of our code.\n",
        "\n",
        "We exchange the matrices between Numpy and our program using CSV files.\n",
        "First, we write our test program in C, which reads the input matrices\n",
        "from CSV files and writes the result to another CSV file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOqeRa1cqIUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37892e81-1e01-4dd8-fc21-aec9af3bc02c"
      },
      "source": [
        "%%writefile test.cu\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"fmatrix_mult.cu\"\n",
        "\n",
        "int main() {\n",
        "    // read two matrices on the host from csv files\n",
        "    fmatrix B = fmatrix_device_from_csv(\"test_B.csv\");\n",
        "    fmatrix C = fmatrix_device_from_csv(\"test_C.csv\");\n",
        "    // allocate matrix A\n",
        "    fmatrix A = fmatrix_create_on_device(B.rows,C.cols);\n",
        "\n",
        "    // compute A = 3.0*B*C\n",
        "    fmatrix_mult(A,3.0,B,C);\n",
        "\n",
        "    fmatrix_device_to_csv(\"test_A.csv\",A);\n",
        "\n",
        "    fmatrix_free_on_device(&B);\n",
        "    fmatrix_free_on_device(&C);\n",
        "    fmatrix_free_on_device(&A);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqa38RQK3Yqi"
      },
      "source": [
        "We need to compile our program so that we can call it from Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHQZL5WqqP11"
      },
      "source": [
        "!nvcc -arch=sm_35 -Wno-deprecated-gpu-targets -g -G -I /usr/local/cuda/samples/common/inc/ -L/usr/local/cuda/include test.cu fmatrix.cu cuda_stuff.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "id": "SJfXbzBVXzhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McLNjYZT3dqq"
      },
      "source": [
        "Now comes the test program in Python. We create test inputs, save them\n",
        "to CSV files, then call our test code, read its output from a CSV file.\n",
        "Then we carry out the same computation in Numpy and compare its result\n",
        "with our test output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85VT8kA8no5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277c64dd-60ab-4778-d822-c5430f465ef2"
      },
      "source": [
        "import numpy as np\n",
        "# create test inputs\n",
        "B = np.array([[1,2,3],[4,5,6]])\n",
        "C = np.array([[7,8],[9,10],[11,12]])\n",
        "# and write them to a file\n",
        "np.savetxt(\"test_B.csv\",B,delimiter=',')\n",
        "np.savetxt(\"test_C.csv\",C,delimiter=',')\n",
        "# call test code\n",
        "!./a.out\n",
        "# read the result of the test code\n",
        "# Note: ndmin=2 since we want a 2D-matrix \n",
        "#       (otherwise it can be flattend to a vector)\n",
        "A_test = np.loadtxt(\"test_A.csv\",delimiter=',',ndmin=2)\n",
        "print(\"From C code:\\n\",A_test)\n",
        "# compute the correct result\n",
        "A = 3.0*B@C\n",
        "print(\"From Numpy code:\\n\",A)\n",
        "# compare correct result with test output\n",
        "result = np.allclose(A,A_test)\n",
        "print(\"Test passed?\", result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From C code:\n",
            " [[174. 192.]\n",
            " [417. 462.]]\n",
            "From Numpy code:\n",
            " [[174. 192.]\n",
            " [417. 462.]]\n",
            "Test passed? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaqKIQjpB5P0"
      },
      "source": [
        "## Random Test Inputs (with Numpy)\n",
        "\n",
        "How do we pick good test inputs? Did we think of all tricky situations (say, matrices that are column or row vectors)?\n",
        "Instead of manually choosing test inputs, we can carry out a (potentially large) number of random tests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lvmrFnyCaEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8b08e1-f389-4956-9e63-0d1dfb83c13e"
      },
      "source": [
        "%%time\n",
        "import numpy as np\n",
        "from random import randint\n",
        "\n",
        "nb_tests = 50\n",
        "max_dimension = 5\n",
        "\n",
        "for i in range(nb_tests):\n",
        "  # create test inputs\n",
        "  # choose random matrix dimensions\n",
        "  n = randint(1,max_dimension)\n",
        "  m = randint(1,max_dimension)\n",
        "  k = randint(1,max_dimension)\n",
        "  B = np.random.rand(n,k)\n",
        "  C = np.random.rand(k,m)\n",
        "  # and write them to a file\n",
        "  np.savetxt(\"test_B.csv\",B,delimiter=',')\n",
        "  np.savetxt(\"test_C.csv\",C,delimiter=',')\n",
        "  # call test code\n",
        "  !./a.out\n",
        "  # read the result of the test code\n",
        "  A_test = np.loadtxt(\"test_A.csv\",delimiter=',',ndmin=2)\n",
        "  # print(\"From C code:\\n\",A_test)\n",
        "  # compute the correct result\n",
        "  A = 3.0*B@C\n",
        "  # print(\"From Numpy code:\\n\",A)\n",
        "  # compare correct result with test output\n",
        "  result = np.allclose(A,A_test)\n",
        "  if not result:\n",
        "    print(\"Wrong test result:\")\n",
        "    print(\"B:\\n\",B)\n",
        "    print(\"C:\\n\",C)\n",
        "    print(\"expected:\\n\",A)\n",
        "    print(\"got wrong result:\\n\",A_test)\n",
        "    break\n",
        "if result:\n",
        "  print(\"All random \",nb_tests,\" test passed.\")\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All random  50  test passed.\n",
            "CPU times: user 419 ms, sys: 413 ms, total: 832 ms\n",
            "Wall time: 11.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17aUKkNJqTDZ"
      },
      "source": [
        "# Debugging\n",
        "We assume that you already compiled with debugging info on the host (`-g`) and device (`-G`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkuaGO10rRm9"
      },
      "source": [
        "Run the debugger cuda-gdb, stopping at the first error that is detected. Shows first the call stack on the GPU, the values of local variables, then the call stack on the host (thread 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ8nAtzGTRgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e1aecf2-2312-41fa-d1f1-b5c251d9a05f"
      },
      "source": [
        "! printf \"set cuda memcheck on\\nset cuda api_failures stop\\ncatch throw\\nr\\nbt\\ninfo locals\\nthread 1\\nbt\\n\" > tmp.txt\n",
        "! cat tmp.txt\n",
        "! cuda-gdb -batch -x tmp.txt ./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set cuda memcheck on\n",
            "set cuda api_failures stop\n",
            "catch throw\n",
            "r\n",
            "bt\n",
            "info locals\n",
            "thread 1\n",
            "bt\n",
            "Catchpoint 1 (throw)\n",
            "warning: Error disabling address space randomization: Operation not permitted\n",
            "[Thread debugging using libthread_db enabled]\n",
            "Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n",
            "[Detaching after fork from child process 899]\n",
            "[New Thread 0x7ffbce364700 (LWP 903)]\n",
            "[New Thread 0x7ffbcdb63700 (LWP 904)]\n",
            "[Thread 0x7ffbce364700 (LWP 903) exited]\n",
            "[Thread 0x7ffbd164c000 (LWP 894) exited]\n",
            "[Inferior 1 (process 894) exited normally]\n",
            "tmp.txt:5: Error in sourced command file:\n",
            "No stack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGJ6uVNBVHUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47fe723e-181b-4b82-8e47-adb09c17cc24"
      },
      "source": [
        "!cuda-memcheck ./a.out "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= CUDA-MEMCHECK\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    }
  ]
}